{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6d1ead52",
      "metadata": {},
      "source": [
        "IBEXAI en Google Colab (sin ZIP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bf4f2de",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip -q install pandas numpy scikit-learn yfinance tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13467121",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "companies_code = r'''IBEX35_COMPANIES = {\n",
        "    \"ANA\": \"Acciona\",\n",
        "    \"ANE\": \"Acciona Energía\",\n",
        "    \"ACX\": \"Acerinox\",\n",
        "    \"ACS\": \"ACS\",\n",
        "    \"AENA\": \"Aena\",\n",
        "    \"AMS\": \"Amadeus\",\n",
        "    \"MTS\": \"ArcelorMittal\",\n",
        "    \"SAB\": \"Banco Sabadell\",\n",
        "    \"SAN\": \"Banco Santander\",\n",
        "    \"BKT\": \"Bankinter\",\n",
        "    \"BBVA\": \"BBVA\",\n",
        "    \"CABK\": \"CaixaBank\",\n",
        "    \"CLNX\": \"Cellnex Telecom\",\n",
        "    \"ENG\": \"Enagás\",\n",
        "    \"END\": \"Endesa\",\n",
        "    \"FER\": \"Ferrovial\",\n",
        "    \"FDR\": \"Fluidra\",\n",
        "    \"GRF\": \"Grifols\",\n",
        "    \"IAG\": \"IAG\",\n",
        "    \"IBE\": \"Iberdrola\",\n",
        "    \"ITX\": \"Inditex\",\n",
        "    \"IDR\": \"Indra\",\n",
        "    \"COL\": \"Inmobiliaria Colonial\",\n",
        "    \"LOG\": \"Logista\",\n",
        "    \"MAP\": \"Mapfre\",\n",
        "    \"MRL\": \"Merlin Properties\",\n",
        "    \"NTGY\": \"Naturgy\",\n",
        "    \"PUIG\": \"Puig\",\n",
        "    \"RED\": \"Redeia\",\n",
        "    \"REP\": \"Repsol\",\n",
        "    \"ROVI\": \"Rovi\",\n",
        "    \"SCYR\": \"Sacyr\",\n",
        "    \"SLR\": \"Solaria\",\n",
        "    \"TEF\": \"Telefónica\",\n",
        "    \"UNI\": \"Unicaja Banco\",\n",
        "    \"ABG\": \"Abengoa\",\n",
        "    \"ABE\": \"Abertis Infraestructuras\",\n",
        "    \"ACR\": \"Aceralia\",\n",
        "    \"AGR\": \"Agromán\",\n",
        "    \"AGS\": \"Aguas de Barcelona\",\n",
        "    \"ALM\": \"Almirall\",\n",
        "    \"ALT\": \"Altadis\",\n",
        "    \"AMP\": \"Amper\",\n",
        "    \"A3TV\": \"Antena 3 TV\",\n",
        "    \"LOR\": \"Arcelor\",\n",
        "    \"ARG\": \"Argentaria\",\n",
        "    \"ASL\": \"Asland\",\n",
        "    \"AZC\": \"Asturiana de Zinc\",\n",
        "    \"AUM\": \"Autopistas del Mare Nostrum\",\n",
        "    \"BBV\": \"Banco Bilbao Vizcaya\",\n",
        "    \"CEN\": \"Banco Central\",\n",
        "    \"BCH\": \"Banco Central Hispano\",\n",
        "    \"HIS\": \"Banco Hispano Americano\",\n",
        "    \"POP\": \"Banco Popular\",\n",
        "    \"BTO\": \"Banesto\",\n",
        "    \"BKIA\": \"Bankia\",\n",
        "    \"BME\": \"Bolsas y Mercados Españoles\",\n",
        "    \"CAR\": \"Carrefour\",\n",
        "    \"CEP\": \"CEPSA\",\n",
        "    \"CIE\": \"CIE Automotive\",\n",
        "    \"CIN\": \"Cintra\",\n",
        "    \"CTE\": \"Continente\",\n",
        "    \"ALB\": \"Corporación Financiera Alba\",\n",
        "    \"CTF\": \"Cortefiel\",\n",
        "    \"SEV\": \"Compañía Sevillana de Electricidad\",\n",
        "    \"CRI\": \"Cristalería Española\",\n",
        "    \"DIA\": \"DIA\",\n",
        "    \"DRC\": \"Dragados\",\n",
        "    \"EBA\": \"Ebro Agrícolas\",\n",
        "    \"EBRO\": \"Ebro Foods\",\n",
        "    \"ENC\": \"ENCE Energía y Celulosa\",\n",
        "    \"ARA\": \"Energía e Industrias Aragonesas\",\n",
        "    \"ECR\": \"Ercros\",\n",
        "    \"FAD\": \"Fadesa\",\n",
        "    \"FCC\": \"FCC\",\n",
        "    \"FEC\": \"Fuerzas Eléctricas de Cataluña\",\n",
        "    \"GES\": \"GESA\",\n",
        "    \"MAS\": \"Grupo MásMóvil\",\n",
        "    \"CAN\": \"Hidrocantábrico\",\n",
        "    \"HHU\": \"Huarte\",\n",
        "    \"IBR\": \"Iberdrola Renovables\",\n",
        "    \"IBLA\": \"Iberia\",\n",
        "    \"JAZ\": \"Jazztel\",\n",
        "    \"TL5\": \"Mediaset España\",\n",
        "    \"MVC\": \"Metrovacesa\",\n",
        "    \"TEM\": \"Telefónica Móviles\",\n",
        "    \"NHH\": \"NH Hotel Group\",\n",
        "    \"OHL\": \"OHL\",\n",
        "    \"PHM\": \"PharmaMar\",\n",
        "    \"GPP\": \"Picking Pack\",\n",
        "    \"VDR\": \"Portland Valderrivas\",\n",
        "    \"PRS\": \"Prisa\",\n",
        "    \"PSG\": \"Prosegur\",\n",
        "    \"PRY\": \"Pryca\",\n",
        "    \"PUL\": \"Puleva\",\n",
        "    \"RAD\": \"Radiotrónica\",\n",
        "    \"SAR\": \"Sarrió\",\n",
        "    \"SGRE\": \"Siemens Gamesa Renewable Energy\",\n",
        "    \"SGC\": \"Sogecable\",\n",
        "    \"TRE\": \"Técnicas Reunidas\",\n",
        "    \"TPI\": \"Telefónica Publicidad e Información\",\n",
        "    \"TPZ\": \"Telepizza\",\n",
        "    \"TRR\": \"Terra Networks\",\n",
        "    \"TUB\": \"Tubacex\",\n",
        "    \"URA\": \"Uralita\",\n",
        "    \"UNF\": \"Unión Fenosa\",\n",
        "    \"URB\": \"Urbis\",\n",
        "    \"VIS\": \"Viscofan\",\n",
        "    \"ZOT\": \"Zardoya Otis\",\n",
        "    \"ZEL\": \"Zeltia\"\n",
        "}\n",
        "\n",
        "IBEX35_SECTORS = {\n",
        "    \"ANA\": \"Industrials\",\n",
        "    \"ANE\": \"Renewables\",\n",
        "    \"ACX\": \"Materials\",\n",
        "    \"ACS\": \"Industrials\",\n",
        "    \"AENA\": \"Industrials\",\n",
        "    \"AMS\": \"Technology\",\n",
        "    \"MTS\": \"Materials\",\n",
        "    \"SAB\": \"Financials\",\n",
        "    \"SAN\": \"Financials\",\n",
        "    \"BKT\": \"Financials\",\n",
        "    \"BBVA\": \"Financials\",\n",
        "    \"CABK\": \"Financials\",\n",
        "    \"CLNX\": \"Telecom\",\n",
        "    \"ENG\": \"Utilities\",\n",
        "    \"END\": \"Energy\",\n",
        "    \"FER\": \"Industrials\",\n",
        "    \"FDR\": \"Industrials\",\n",
        "    \"GRF\": \"Healthcare\",\n",
        "    \"IAG\": \"Airlines\",\n",
        "    \"IBE\": \"Energy\",\n",
        "    \"ITX\": \"Consumer\",\n",
        "    \"IDR\": \"Technology\",\n",
        "    \"COL\": \"RealEstate\",\n",
        "    \"LOG\": \"Logistics\",\n",
        "    \"MAP\": \"Financials\",\n",
        "    \"MRL\": \"RealEstate\",\n",
        "    \"NTGY\": \"Energy\",\n",
        "    \"PUIG\": \"Consumer\",\n",
        "    \"RED\": \"Utilities\",\n",
        "    \"REP\": \"Energy\",\n",
        "    \"ROVI\": \"Healthcare\",\n",
        "    \"SCYR\": \"Industrials\",\n",
        "    \"SLR\": \"Renewables\",\n",
        "    \"TEF\": \"Telecom\",\n",
        "    \"UNI\": \"Financials\",\n",
        "    \"ABG\": \"Industrials\",\n",
        "    \"ABE\": \"Industrials\",\n",
        "    \"ACR\": \"Materials\",\n",
        "    \"AGR\": \"Industrials\",\n",
        "    \"AGS\": \"Utilities\",\n",
        "    \"ALM\": \"Healthcare\",\n",
        "    \"ALT\": \"Consumer\",\n",
        "    \"AMP\": \"Technology\",\n",
        "    \"A3TV\": \"Media\",\n",
        "    \"LOR\": \"Materials\",\n",
        "    \"ARG\": \"Financials\",\n",
        "    \"ASL\": \"Materials\",\n",
        "    \"AZC\": \"Materials\",\n",
        "    \"AUM\": \"Industrials\",\n",
        "    \"BBV\": \"Financials\",\n",
        "    \"CEN\": \"Financials\",\n",
        "    \"BCH\": \"Financials\",\n",
        "    \"HIS\": \"Financials\",\n",
        "    \"POP\": \"Financials\",\n",
        "    \"BTO\": \"Financials\",\n",
        "    \"BKIA\": \"Financials\",\n",
        "    \"BME\": \"Financials\",\n",
        "    \"CAR\": \"Consumer\",\n",
        "    \"CEP\": \"Energy\",\n",
        "    \"CIE\": \"Industrials\",\n",
        "    \"CIN\": \"Industrials\",\n",
        "    \"CTE\": \"Consumer\",\n",
        "    \"ALB\": \"Financials\",\n",
        "    \"CTF\": \"Consumer\",\n",
        "    \"SEV\": \"Utilities\",\n",
        "    \"CRI\": \"Materials\",\n",
        "    \"DIA\": \"Consumer\",\n",
        "    \"DRC\": \"Industrials\",\n",
        "    \"EBA\": \"Consumer\",\n",
        "    \"EBRO\": \"Consumer\",\n",
        "    \"ENC\": \"Materials\",\n",
        "    \"ARA\": \"Materials\",\n",
        "    \"ECR\": \"Materials\",\n",
        "    \"FAD\": \"RealEstate\",\n",
        "    \"FCC\": \"Industrials\",\n",
        "    \"FEC\": \"Utilities\",\n",
        "    \"GES\": \"Utilities\",\n",
        "    \"MAS\": \"Telecom\",\n",
        "    \"CAN\": \"Utilities\",\n",
        "    \"HHU\": \"Industrials\",\n",
        "    \"IBR\": \"Renewables\",\n",
        "    \"IBLA\": \"Airlines\",\n",
        "    \"JAZ\": \"Telecom\",\n",
        "    \"TL5\": \"Media\",\n",
        "    \"MVC\": \"RealEstate\",\n",
        "    \"TEM\": \"Telecom\",\n",
        "    \"NHH\": \"Consumer\",\n",
        "    \"OHL\": \"Industrials\",\n",
        "    \"PHM\": \"Healthcare\",\n",
        "    \"GPP\": \"Technology\",\n",
        "    \"VDR\": \"Materials\",\n",
        "    \"PRS\": \"Media\",\n",
        "    \"PSG\": \"Industrials\",\n",
        "    \"PRY\": \"Consumer\",\n",
        "    \"PUL\": \"Consumer\",\n",
        "    \"RAD\": \"Technology\",\n",
        "    \"SAR\": \"Materials\",\n",
        "    \"SGRE\": \"Renewables\",\n",
        "    \"SGC\": \"Media\",\n",
        "    \"TRE\": \"Industrials\",\n",
        "    \"TPI\": \"Media\",\n",
        "    \"TPZ\": \"Consumer\",\n",
        "    \"TRR\": \"Telecom\",\n",
        "    \"TUB\": \"Materials\",\n",
        "    \"URA\": \"Materials\",\n",
        "    \"UNF\": \"Utilities\",\n",
        "    \"URB\": \"RealEstate\",\n",
        "    \"VIS\": \"Consumer\",\n",
        "    \"ZOT\": \"Industrials\",\n",
        "    \"ZEL\": \"Healthcare\"\n",
        "}\n",
        "'''\n",
        "\n",
        "factors_code = r'''import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def compute_factors(market_df):\n",
        "    df = market_df.copy()\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "    df = df.sort_values(['Company', 'Date'])\n",
        "    price_col = 'Adj Close' if 'Adj Close' in df.columns else 'Close'\n",
        "    df['Price'] = pd.to_numeric(df[price_col], errors='coerce')\n",
        "    df['Volume'] = pd.to_numeric(df['Volume'], errors='coerce').fillna(0.0)\n",
        "    df['ret_1d'] = df.groupby('Company')['Price'].pct_change(1)\n",
        "    market_ret = df.groupby('Date')['ret_1d'].mean().rename('market_ret')\n",
        "    df = df.merge(market_ret, on='Date', how='left')\n",
        "    out = []\n",
        "    for company, g in df.groupby('Company'):\n",
        "        g = g.copy()\n",
        "        g['momentum_1w'] = g['Price'].pct_change(5)\n",
        "        g['momentum_1m'] = g['Price'].pct_change(20)\n",
        "        g['momentum_3m'] = g['Price'].pct_change(65)\n",
        "        g['momentum_6m'] = g['Price'].pct_change(130)\n",
        "        g['vol_1m'] = g['ret_1d'].rolling(20).std()\n",
        "        g['vol_3m'] = g['ret_1d'].rolling(65).std()\n",
        "        g['avg_volume_20'] = g['Volume'].rolling(20).mean()\n",
        "        g['liquidity_flag'] = (g['avg_volume_20'] > g['avg_volume_20'].quantile(0.2)).astype(int)\n",
        "        high_252 = g['Price'].rolling(252).max()\n",
        "        g['dist_52w_high'] = g['Price'] / high_252 - 1\n",
        "        w = 65\n",
        "        cov = g[['ret_1d','market_ret']].rolling(w).cov().unstack().iloc[:,1]\n",
        "        var_m = g['market_ret'].rolling(w).var()\n",
        "        g['beta_3m'] = cov / (var_m + 1e-9)\n",
        "        m = g['Date'].dt.month\n",
        "        g['month_sin'] = np.sin(2*np.pi*m/12.0)\n",
        "        g['month_cos'] = np.cos(2*np.pi*m/12.0)\n",
        "        g['turn_of_month'] = ((g['Date'].dt.day <= 3) | (g['Date'].dt.day >= 28)).astype(int)\n",
        "        out.append(g)\n",
        "    return pd.concat(out)\n",
        "'''\n",
        "\n",
        "market_data_code = r'''import yfinance as yf\n",
        "import pandas as pd\n",
        "from companies import IBEX35_COMPANIES\n",
        "from tqdm import tqdm\n",
        "\n",
        "def fetch_market_data():\n",
        "    print(\"Fetching market data for IBEX35 companies (including historical members)...\")\n",
        "    all_data = []\n",
        "    override_tickers = {\n",
        "        \"MTS\": [\"MTS.MC\"],\n",
        "        \"IBE\": [\"IBE.MC\"]\n",
        "    }\n",
        "    for ticker_code, company_name in tqdm(IBEX35_COMPANIES.items()):\n",
        "        candidates = override_tickers.get(ticker_code, [f\"{ticker_code}.MC\", ticker_code])\n",
        "        fetched = False\n",
        "        for yf_ticker in candidates:\n",
        "            try:\n",
        "                df = yf.download(yf_ticker, start=\"2005-01-01\", interval=\"1d\", progress=False, auto_adjust=False)\n",
        "                if not df.empty:\n",
        "                    df = df.reset_index()\n",
        "                    df['Ticker'] = ticker_code\n",
        "                    df['Company'] = company_name\n",
        "                    if isinstance(df.columns, pd.MultiIndex):\n",
        "                        df.columns = [c[0] if c[0] != 'Price' else c[1] for c in df.columns]\n",
        "                    if 'Date' not in df.columns and df.index.name == 'Date':\n",
        "                        df = df.reset_index()\n",
        "                    all_data.append(df)\n",
        "                    fetched = True\n",
        "                    break\n",
        "            except Exception:\n",
        "                continue\n",
        "        if not fetched:\n",
        "            print(f\"No data found for {company_name} ({ticker_code})\")\n",
        "    if all_data:\n",
        "        final_df = pd.concat(all_data, ignore_index=True)\n",
        "        output_file = 'ibex35_market_data.csv'\n",
        "        final_df.to_csv(output_file, index=False)\n",
        "        print(f\"Market data saved to {output_file}. Total rows: {len(final_df)}\")\n",
        "        return final_df\n",
        "    else:\n",
        "        print(\"No data fetched.\")\n",
        "        return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    fetch_market_data()\n",
        "'''\n",
        "\n",
        "backtesting_code = r'''import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from datetime import timedelta\n",
        "from factors import compute_factors\n",
        "from companies import IBEX35_SECTORS\n",
        "\n",
        "def prepare_merged(market_csv='ibex35_market_data.csv', sentiment_csv='ibex35_news_sentiment.csv', use_sentiment=True):\n",
        "    m = pd.read_csv(market_csv)\n",
        "    s = pd.read_csv(sentiment_csv)\n",
        "    m['Date'] = pd.to_datetime(m['Date'])\n",
        "    s['date'] = pd.to_datetime(s['date'], dayfirst=True, errors='coerce')\n",
        "    s = s.dropna(subset=['date'])\n",
        "    s = s[['date','ticker','company','sector','calibrated_score']].rename(columns={'date':'Date'})\n",
        "    daily = s.groupby(['company','Date'])['calibrated_score'].mean().reset_index().rename(columns={'calibrated_score':'Daily_Sentiment', 'company':'Company'})\n",
        "    df = pd.merge(m, daily, on=['Company','Date'], how='left')\n",
        "    price_col = 'Adj Close' if 'Adj Close' in df.columns else 'Close'\n",
        "    df = df[df[price_col].notna() & (df[price_col] > 0)]\n",
        "    if use_sentiment:\n",
        "        df['Daily_Sentiment'] = df.groupby('Company')['Daily_Sentiment'].ffill(limit=5).fillna(0.0)\n",
        "    f = compute_factors(df)\n",
        "    cols = ['momentum_1w','momentum_1m','momentum_3m','momentum_6m','vol_1m','vol_3m','avg_volume_20','liquidity_flag']\n",
        "    df[cols] = f[cols]\n",
        "    df['dist_52w_high'] = f['dist_52w_high']\n",
        "    df['beta_3m'] = f['beta_3m']\n",
        "    df['month_sin'] = f['month_sin']\n",
        "    df['month_cos'] = f['month_cos']\n",
        "    df['turn_of_month'] = f['turn_of_month']\n",
        "    if use_sentiment:\n",
        "        df['Sentiment_30D'] = df.groupby('Company')['Daily_Sentiment'].rolling(30).mean().reset_index(level=0, drop=True)\n",
        "        df['Sentiment_7D'] = df.groupby('Company')['Daily_Sentiment'].rolling(7).mean().reset_index(level=0, drop=True)\n",
        "    df['Return_1D'] = df.groupby('Company')[price_col].pct_change(1)\n",
        "    df['Return_1M'] = df.groupby('Company')[price_col].pct_change(20)\n",
        "    df['Forward_Return_1W'] = df.groupby('Company')[price_col].transform(lambda x: x.shift(-5) / x - 1)\n",
        "    df['Target_1W'] = df['Forward_Return_1W'] - df.groupby('Date')['Forward_Return_1W'].transform('mean')\n",
        "    return df\n",
        "\n",
        "def select_universe(df_row, sector_counts, max_per_sector):\n",
        "    return sector_counts.get(df_row['sector'], 0) < max_per_sector and df_row['liquidity_flag'] == 1\n",
        "\n",
        "def backtest_walkforward(train_years=5, top_n=6, max_per_sector=2, max_weight=0.2, use_sentiment=True, confidence_threshold=0.005, start_date=\"2005-01-01\"):\n",
        "    df = prepare_merged(use_sentiment=use_sentiment)\n",
        "    if start_date is not None:\n",
        "        df = df[df['Date'] >= pd.to_datetime(start_date)]\n",
        "    base_cols = ['momentum_1w','momentum_1m','momentum_3m','momentum_6m','vol_1m','vol_3m','avg_volume_20','Return_1M','dist_52w_high','beta_3m','month_sin','month_cos','turn_of_month']\n",
        "    if use_sentiment:\n",
        "        df = df.dropna(subset=base_cols + ['Sentiment_7D','Sentiment_30D'])\n",
        "        feature_cols = base_cols + ['Sentiment_7D','Sentiment_30D']\n",
        "    else:\n",
        "        df = df.dropna(subset=base_cols)\n",
        "        feature_cols = base_cols\n",
        "    df['Weekday'] = df['Date'].dt.weekday\n",
        "    trade_dates = sorted(df[df['Weekday'] == 4]['Date'].unique())\n",
        "    if start_date is not None:\n",
        "        start_dt = pd.to_datetime(start_date)\n",
        "        start_idx = next((i for i, d in enumerate(trade_dates) if d >= start_dt), len(trade_dates))\n",
        "    else:\n",
        "        start_idx = 0\n",
        "        while start_idx < len(trade_dates) and (trade_dates[start_idx] - trade_dates[0]).days < train_years*365:\n",
        "            start_idx += 1\n",
        "    print(f\"Iniciando Backtest Semanal (Viernes con datos del día previo) - {len(trade_dates)-start_idx} semanas...\")\n",
        "    period_returns = []\n",
        "    benchmark_returns = []\n",
        "    trade_log = []\n",
        "    model = None\n",
        "    for i in range(start_idx, len(trade_dates) - 1):\n",
        "        curr_date = trade_dates[i]\n",
        "        next_date = trade_dates[i+1]\n",
        "        feature_date = df[df['Date'] < curr_date]['Date'].max()\n",
        "        if pd.isna(feature_date):\n",
        "            continue\n",
        "        print(f\"Re-entrenando modelo en {curr_date.date()}...\")\n",
        "        train_limit_date = feature_date - timedelta(days=7)\n",
        "        train_df = df[df['Date'] <= train_limit_date].dropna(subset=['Target_1W'])\n",
        "        if len(train_df) > 100:\n",
        "            X = train_df[feature_cols]\n",
        "            y = train_df['Target_1W']\n",
        "            model = RandomForestRegressor(\n",
        "                n_estimators=100,\n",
        "                max_depth=12,\n",
        "                min_samples_leaf=5,\n",
        "                max_features='sqrt',\n",
        "                random_state=42,\n",
        "                n_jobs=-1\n",
        "            )\n",
        "            model.fit(X, y)\n",
        "        if model is None:\n",
        "            continue\n",
        "        predict_df = df[df['Date'] == feature_date].copy()\n",
        "        if predict_df.empty:\n",
        "            continue\n",
        "        price_col = 'Adj Close' if 'Adj Close' in df.columns else 'Close'\n",
        "        next_prices = df[df['Date'] == next_date].set_index('Company')[price_col]\n",
        "        curr_prices = df[df['Date'] == curr_date].set_index('Company')[price_col]\n",
        "        if curr_prices.empty or next_prices.empty:\n",
        "            period_returns.append(0.0)\n",
        "            benchmark_returns.append(0.0)\n",
        "            continue\n",
        "        common_companies = curr_prices.index.intersection(next_prices.index)\n",
        "        if len(common_companies) == 0:\n",
        "            period_returns.append(0.0)\n",
        "            benchmark_returns.append(0.0)\n",
        "            continue\n",
        "        market_rets = (next_prices[common_companies] / curr_prices[common_companies]) - 1\n",
        "        market_period_return = market_rets.mean()\n",
        "        sector_map = predict_df['Company'].map(lambda c: IBEX35_SECTORS.get(predict_df[predict_df['Company']==c]['Ticker'].iloc[0], 'Unknown'))\n",
        "        predict_df['sector'] = sector_map\n",
        "        Xp = predict_df[feature_cols]\n",
        "        predict_df['pred'] = model.predict(Xp)\n",
        "        predict_df = predict_df.sort_values('pred', ascending=False)\n",
        "        sector_counts = {}\n",
        "        selected = []\n",
        "        for _, row in predict_df.iterrows():\n",
        "            if row['Company'] not in common_companies: continue\n",
        "            sec = row['sector']\n",
        "            sector_counts.setdefault(sec, 0)\n",
        "            if select_universe(row, sector_counts, max_per_sector):\n",
        "                selected.append(row)\n",
        "                sector_counts[sec] += 1\n",
        "            if len(selected) >= top_n:\n",
        "                break\n",
        "        if len(selected) == 0:\n",
        "            strat_ret = 0.0\n",
        "        else:\n",
        "            sel_df = pd.DataFrame(selected)\n",
        "            avg_pred = sel_df['pred'].mean()\n",
        "            if avg_pred < confidence_threshold:\n",
        "                strat_ret = 0.0\n",
        "            else:\n",
        "                raw_weights = sel_df['pred'].clip(lower=0.0).to_numpy()\n",
        "                if raw_weights.sum() == 0:\n",
        "                    strat_ret = 0.0\n",
        "                else:\n",
        "                    weights = raw_weights / raw_weights.sum()\n",
        "                    if max_weight is not None:\n",
        "                        weights = np.minimum(weights, max_weight)\n",
        "                        weights = weights / weights.sum()\n",
        "                    sel_rets = market_rets[sel_df['Company']].values\n",
        "                    strat_ret = float(np.sum(weights * sel_rets))\n",
        "                    for idx, row in sel_df.iterrows():\n",
        "                        real_ret = market_rets[row['Company']]\n",
        "                        trade_log.append({\n",
        "                            'Date': curr_date,\n",
        "                            'Ticker': row.get('Ticker', 'Unknown'),\n",
        "                            'Company': row['Company'],\n",
        "                            'Sector': row['sector'],\n",
        "                            'Weight': float(weights[sel_df.index.get_loc(idx)]),\n",
        "                            'Predicted_Return': row['pred'],\n",
        "                            'Realized_Return': real_ret,\n",
        "                            'Market_Return': market_period_return,\n",
        "                            'Alpha': real_ret - market_period_return\n",
        "                        })\n",
        "        period_returns.append(strat_ret)\n",
        "        benchmark_returns.append(market_period_return)\n",
        "    if not period_returns:\n",
        "        return pd.DataFrame()\n",
        "    trades_df = pd.DataFrame(trade_log)\n",
        "    trades_df.to_csv('backtest_trades.csv', index=False)\n",
        "    print(f\"\\nGuardado registro detallado de operaciones en 'backtest_trades.csv' ({len(trades_df)} registros)\")\n",
        "    equity_curve = [10000.0]\n",
        "    benchmark_curve = [10000.0]\n",
        "    for r, b_r in zip(period_returns, benchmark_returns):\n",
        "        equity_curve.append(equity_curve[-1] * (1 + r))\n",
        "        benchmark_curve.append(benchmark_curve[-1] * (1 + b_r))\n",
        "    total_return = (equity_curve[-1] / 10000.0) - 1\n",
        "    benchmark_total_return = (benchmark_curve[-1] / 10000.0) - 1\n",
        "    years = (trade_dates[-1] - trade_dates[start_idx]).days / 365.0\n",
        "    cagr = (equity_curve[-1] / 10000.0) ** (1/years) - 1 if years > 0 else 0\n",
        "    benchmark_cagr = (benchmark_curve[-1] / 10000.0) ** (1/years) - 1 if years > 0 else 0\n",
        "    alpha_total = total_return - benchmark_total_return\n",
        "    alpha_annual = cagr - benchmark_cagr\n",
        "    print(f\"\\n--- Resultados Backtest ({years:.1f} años) ---\")\n",
        "    print(f\"Capital Final Estrategia: {equity_curve[-1]:.2f}€ (Inicio: 10,000€)\")\n",
        "    print(f\"Capital Final Mercado:    {benchmark_curve[-1]:.2f}€\")\n",
        "    print(f\"Retorno Total: {total_return*100:.2f}% (Mercado: {benchmark_total_return*100:.2f}%)\")\n",
        "    print(f\"CAGR (Anual):  {cagr*100:.2f}% (Mercado: {benchmark_cagr*100:.2f}%)\")\n",
        "    print(f\"Alpha Total:   {alpha_total*100:.2f}%\")\n",
        "    print(f\"Alpha Anual:   {alpha_annual*100:.2f}%\")\n",
        "    return pd.DataFrame({'Date': trade_dates[start_idx:][:len(equity_curve)], 'Equity': equity_curve, 'Benchmark': benchmark_curve})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    backtest_walkforward()\n",
        "'''\n",
        "\n",
        "with open('companies.py', 'w', encoding='utf-8') as f:\n",
        "    f.write(companies_code)\n",
        "with open('factors.py', 'w', encoding='utf-8') as f:\n",
        "    f.write(factors_code)\n",
        "with open('market_data.py', 'w', encoding='utf-8') as f:\n",
        "    f.write(market_data_code)\n",
        "with open('backtesting.py', 'w', encoding='utf-8') as f:\n",
        "    f.write(backtesting_code)\n",
        "print(\"Archivos generados\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not os.path.exists(\"ibex35_news_sentiment.csv\"):\n",
        "    from google.colab import files\n",
        "    files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python market_data.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python backtesting.py"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
